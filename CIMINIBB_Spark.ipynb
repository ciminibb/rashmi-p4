{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\benci\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.5.3)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\benci\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Run a shell command to ensure pyspark is downloaded in the Python environment.\n",
    "!python -m pip install pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import year, month, col, row_number, trim, input_file_name, split, mean, count, when, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Spark Session, which is an entry point to the PySpark application.\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Weather Insights\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV files using filepath wildcard to open all files of the same type at once.\n",
    "# In some analysis we are concerned with the dataset to which specific data belongs.\n",
    "# To capture that information, we can add a filename column to the data frame on creation.\n",
    "filepath = \"C:/Users/benci/College/Class/6th Year/2024 Fall (CS)/INTRO TO CLOUD COMPUTING/Projects/P4/rashmi-p4/data/*.csv\"\n",
    "dataframe = spark.read.option(\"header\", \"true\").option(\"mode\", \"DROPMALFORMED\").csv(filepath).withColumn(\"filename\", input_file_name())\n",
    "\n",
    "# It's beneficial to trim the filename for readability in results, hence the following line.\n",
    "# To be clear, it splits the filename by delimiters then selects the last listed value, the\n",
    "# actual name.\n",
    "dataframe = dataframe.withColumn(\"filename\", split(dataframe[\"filename\"], \"/\")[15]) # Indexing by -1 wasn't working???\n",
    "\n",
    "# Looking at the printed schema, it's clear that all columns have string type by default.\n",
    "# That won't work, as we need to do numeric computations on some values. So, I'll be cleaning\n",
    "# the data by casting essential columns to floats and removing empty values, where needed.\n",
    "dataframe = dataframe.withColumn(\"MAX\", trim(col(\"MAX\")).cast(\"float\")) # Convert MAX to float.\n",
    "dataframe = dataframe.withColumn(\"MIN\", trim(col(\"MIN\")).cast(\"float\")) # Convert MIN to float.\n",
    "dataframe = dataframe.withColumn(\"PRCP\", trim(col(\"PRCP\")).cast(\"float\")) # Convert PRCP to float.\n",
    "# I'M NOT TYPE CASTING \"GUST\" BECAUSE IT CAUSES FLOAT PRECISION ERRORS.\n",
    "dataframe = dataframe.withColumn(\"DATE\", col(\"DATE\").cast(\"date\")) # Convert DATE to DATE.\n",
    "\n",
    "dataframe = dataframe \\\n",
    "    .withColumn(\"YEAR\", year(col(\"DATE\"))) \\\n",
    "    .withColumn(\"MONTH\", month(col(\"DATE\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- STATION: string (nullable = true)\n",
      " |-- DATE: date (nullable = true)\n",
      " |-- LATITUDE: string (nullable = true)\n",
      " |-- LONGITUDE: string (nullable = true)\n",
      " |-- ELEVATION: string (nullable = true)\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- TEMP: string (nullable = true)\n",
      " |-- TEMP_ATTRIBUTES: string (nullable = true)\n",
      " |-- DEWP: string (nullable = true)\n",
      " |-- DEWP_ATTRIBUTES: string (nullable = true)\n",
      " |-- SLP: string (nullable = true)\n",
      " |-- SLP_ATTRIBUTES: string (nullable = true)\n",
      " |-- STP: string (nullable = true)\n",
      " |-- STP_ATTRIBUTES: string (nullable = true)\n",
      " |-- VISIB: string (nullable = true)\n",
      " |-- VISIB_ATTRIBUTES: string (nullable = true)\n",
      " |-- WDSP: string (nullable = true)\n",
      " |-- WDSP_ATTRIBUTES: string (nullable = true)\n",
      " |-- MXSPD: string (nullable = true)\n",
      " |-- GUST: string (nullable = true)\n",
      " |-- MAX: float (nullable = true)\n",
      " |-- MAX_ATTRIBUTES: string (nullable = true)\n",
      " |-- MIN: float (nullable = true)\n",
      " |-- MIN_ATTRIBUTES: string (nullable = true)\n",
      " |-- PRCP: float (nullable = true)\n",
      " |-- PRCP_ATTRIBUTES: string (nullable = true)\n",
      " |-- SNDP: string (nullable = true)\n",
      " |-- FRSHTT: string (nullable = true)\n",
      " |-- filename: string (nullable = true)\n",
      " |-- YEAR: integer (nullable = true)\n",
      " |-- MONTH: integer (nullable = true)\n",
      "\n",
      "+-----------+----------+--------+---------+---------+--------------------+------+---------------+------+---------------+------+--------------+-----+--------------+-----+----------------+-----+---------------+-----+-----+----+--------------+----+--------------+----+---------------+-----+------+--------------------+----+-----+\n",
      "|    STATION|      DATE|LATITUDE|LONGITUDE|ELEVATION|                NAME|  TEMP|TEMP_ATTRIBUTES|  DEWP|DEWP_ATTRIBUTES|   SLP|SLP_ATTRIBUTES|  STP|STP_ATTRIBUTES|VISIB|VISIB_ATTRIBUTES| WDSP|WDSP_ATTRIBUTES|MXSPD| GUST| MAX|MAX_ATTRIBUTES| MIN|MIN_ATTRIBUTES|PRCP|PRCP_ATTRIBUTES| SNDP|FRSHTT|            filename|YEAR|MONTH|\n",
      "+-----------+----------+--------+---------+---------+--------------------+------+---------------+------+---------------+------+--------------+-----+--------------+-----+----------------+-----+---------------+-----+-----+----+--------------+----+--------------+----+---------------+-----+------+--------------------+----+-----+\n",
      "|72429793812|2016-01-01|  39.106|-84.41609|    144.8|CINCINNATI MUNICI...|  32.7|             24|  23.6|             24|1026.6|            22|008.0|            24| 10.0|              24|  9.4|             24| 15.0| 19.0|39.9|              |28.0|              | 0.0|              G|999.9|000000|2016_72429793812.csv|2016|    1|\n",
      "|72429793812|2016-01-02|  39.106|-84.41609|    144.8|CINCINNATI MUNICI...|  32.6|             24|  24.0|             24|1023.6|            24|005.0|            24| 10.0|              24|  7.5|             24| 12.0|999.9|43.0|              |25.0|              | 0.0|              G|999.9|000000|2016_72429793812.csv|2016|    1|\n",
      "|72429793812|2016-01-03|  39.106|-84.41609|    144.8|CINCINNATI MUNICI...|  32.6|             24|  25.5|             24|1018.7|            23|000.4|            24| 10.0|              24|  6.3|             24| 11.1| 15.9|43.0|              |25.0|              | 0.0|              G|999.9|000000|2016_72429793812.csv|2016|    1|\n",
      "|72429793812|2016-01-04|  39.106|-84.41609|    144.8|CINCINNATI MUNICI...|  32.0|             24|  22.5|             24|1026.6|            18|007.8|            24| 10.0|              24|  7.9|             24| 11.1|999.9|37.0|              |26.1|              | 0.0|              G|999.9|001000|2016_72429793812.csv|2016|    1|\n",
      "|72429793812|2016-01-05|  39.106|-84.41609|    144.8|CINCINNATI MUNICI...|  24.5|             24|  13.9|             24|1036.4|            24|017.5|            24| 10.0|              24|  3.5|             24|  8.9|999.9|36.0|              |16.0|              | 0.0|              G|999.9|000000|2016_72429793812.csv|2016|    1|\n",
      "+-----------+----------+--------+---------+---------+--------------------+------+---------------+------+---------------+------+--------------+-----+--------------+-----+----------------+-----+---------------+-----+-----+----+--------------+----+--------------+----+---------------+-----+------+--------------------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check if the data was loaded correctly by printing the schema and a few rows.\n",
    "dataframe.printSchema()\n",
    "dataframe.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|filename            |count|\n",
      "+--------------------+-----+\n",
      "|2020_72429793812.csv|366  |\n",
      "|2016_72429793812.csv|366  |\n",
      "|2017_72429793812.csv|365  |\n",
      "|2015_72429793812.csv|365  |\n",
      "|2018_72429793812.csv|365  |\n",
      "|2019_72429793812.csv|365  |\n",
      "|2022_72429793812.csv|365  |\n",
      "|2021_72429793812.csv|365  |\n",
      "|2020_99495199999.csv|365  |\n",
      "|2023_72429793812.csv|365  |\n",
      "|2018_99495199999.csv|363  |\n",
      "|2015_99495199999.csv|355  |\n",
      "|2019_99495199999.csv|345  |\n",
      "|2024_72429793812.csv|301  |\n",
      "|2023_99495199999.csv|276  |\n",
      "|2017_99495199999.csv|283  |\n",
      "|2022_99495199999.csv|259  |\n",
      "|2024_99495199999.csv|133  |\n",
      "|2021_99495199999.csv|104  |\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group by filename and count rows\n",
    "file_counts = dataframe.groupBy(\"filename\").count()\n",
    "file_counts.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+-----+\n",
      "|    STATION|                NAME|      DATE|  MAX|\n",
      "+-----------+--------------------+----------+-----+\n",
      "|72429793812|CINCINNATI MUNICI...|2024-08-30|100.9|\n",
      "|72429793812|CINCINNATI MUNICI...|2018-07-04| 96.1|\n",
      "|72429793812|CINCINNATI MUNICI...|2022-06-14| 96.1|\n",
      "|72429793812|CINCINNATI MUNICI...|2023-08-23| 96.1|\n",
      "|72429793812|CINCINNATI MUNICI...|2019-09-30| 95.0|\n",
      "|72429793812|CINCINNATI MUNICI...|2021-08-12| 95.0|\n",
      "|72429793812|CINCINNATI MUNICI...|2016-07-24| 93.9|\n",
      "|72429793812|CINCINNATI MUNICI...|2020-07-05| 93.9|\n",
      "|72429793812|CINCINNATI MUNICI...|2015-06-12| 91.9|\n",
      "|72429793812|CINCINNATI MUNICI...|2017-07-22| 91.9|\n",
      "+-----------+--------------------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL COMPUTES THE HOTTEST DAY IN EACH YEAR\n",
    "\n",
    "# Before doing anything, we need to get rid of any erroneously high temperature readings.\n",
    "# Using my personal discretion, I'm choosing to consider any temperature above 150F as\n",
    "# error.\n",
    "hottest_cleaned = dataframe \\\n",
    "    .filter(col(\"MAX\") < 150)\n",
    "\n",
    "# Create a window specification for ranking the days within each year by their\n",
    "# highest temperature.\n",
    "hottest_window = Window.partitionBy(\"YEAR\").orderBy(col(\"MAX\").desc())\n",
    "\n",
    "# Add a column to store the \"RANK\" of each day. That is, how its high temperature\n",
    "# compared with other days in the same year.\n",
    "hottest_days = hottest_cleaned.withColumn(\"RANK\", row_number().over(hottest_window))\n",
    "\n",
    "# Run a filter to get the single hottest day of each year.\n",
    "hottest_days = hottest_days.filter(col(\"RANK\") == 1) \\\n",
    "    .select(\"STATION\", \"NAME\", \"DATE\", \"MAX\") \\\n",
    "    .orderBy(col(\"MAX\").desc())\n",
    "\n",
    "hottest_days.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+----------+----+\n",
      "|    STATION|                NAME|      DATE| MIN|\n",
      "+-----------+--------------------+----------+----+\n",
      "|72429793812|CINCINNATI MUNICI...|2015-03-06| 3.2|\n",
      "|72429793812|CINCINNATI MUNICI...|2019-03-05|10.0|\n",
      "|72429793812|CINCINNATI MUNICI...|2023-03-15|17.1|\n",
      "|72429793812|CINCINNATI MUNICI...|2022-03-13|18.0|\n",
      "|72429793812|CINCINNATI MUNICI...|2017-03-15|19.0|\n",
      "|72429793812|CINCINNATI MUNICI...|2020-03-01|19.0|\n",
      "|72429793812|CINCINNATI MUNICI...|2018-03-22|21.0|\n",
      "|72429793812|CINCINNATI MUNICI...|2024-03-01|23.0|\n",
      "|72429793812|CINCINNATI MUNICI...|2021-03-02|24.1|\n",
      "|72429793812|CINCINNATI MUNICI...|2016-03-02|26.1|\n",
      "+-----------+--------------------+----------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL COMPUTES THE COLDEST DAY OF EACH YEAR, BUT ONLY FROM MARCH\n",
    "\n",
    "# Run a filter to ensure we're only looking at data from March. There was no obviously\n",
    "# erroneus data for the coldest temperatures, so I didn't worry about filtering it.\n",
    "coldest_cleaned = dataframe \\\n",
    "    .filter(col(\"MONTH\") == 3)\n",
    "\n",
    "# Create a window specification for ranking the days within each year by their\n",
    "# lowest temperature. This time we'll rank in ascending order, so the coldest\n",
    "# days get the highest ranks.\n",
    "coldest_window = Window.partitionBy(\"YEAR\").orderBy(col(\"MIN\").asc())\n",
    "\n",
    "# Add a column to store the \"RANK\" of each day.\n",
    "coldest_days = coldest_cleaned.withColumn(\"RANK\", row_number().over(coldest_window))\n",
    "\n",
    "# Run a filter to get the single hottest day of each year.\n",
    "coldest_days = coldest_days.filter(col(\"RANK\") == 1) \\\n",
    "    .select(\"STATION\", \"NAME\", \"DATE\", \"MIN\") \\\n",
    "    .orderBy(col(\"MIN\").asc())\n",
    "\n",
    "coldest_days.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------------+\n",
      "|                NAME|YEAR| MEAN_PRECIPITATION|\n",
      "+--------------------+----+-------------------+\n",
      "|CINCINNATI MUNICI...|2018|0.15789040991500633|\n",
      "|SEBASTIAN INLET S...|2020|                0.0|\n",
      "+--------------------+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL COMPUTES THE YEAR WITH THE MOST PRECIPITATION AT EACH STATION\n",
    "\n",
    "# Clean erroneous precipitation readings.\n",
    "wettest_cleaned = dataframe \\\n",
    "    .filter(col(\"PRCP\") < 99)\n",
    "\n",
    "# Aggregate the mean precipitation by station and year.\n",
    "wettest_year_at_station = wettest_cleaned \\\n",
    "    .groupBy(\"YEAR\", \"NAME\") \\\n",
    "    .agg(mean(\"PRCP\").alias(\"MEAN_PRECIPITATION\"))\n",
    "    \n",
    "# Rank the mean precipitations in order to find the greatest for both station. Filter\n",
    "# the dataframe for only those top ranked records.\n",
    "wettest_window = Window.partitionBy(\"NAME\").orderBy(col(\"MEAN_PRECIPITATION\").desc())\n",
    "    \n",
    "wettest_year_at_station = wettest_year_at_station \\\n",
    "    .withColumn(\"RANK\", row_number().over(wettest_window)) \\\n",
    "    .filter(col(\"RANK\") == 1) \\\n",
    "    .select(\"NAME\", \"YEAR\", \"MEAN_PRECIPITATION\")\n",
    "\n",
    "wettest_year_at_station.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------------+\n",
      "|                NAME|        MISSING_%|\n",
      "+--------------------+-----------------+\n",
      "|CINCINNATI MUNICI...|39.53488372093023|\n",
      "|SEBASTIAN INLET S...|            100.0|\n",
      "+--------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# THIS CELL COMPUTES THE PERCENTAGE OF MISSING VALUES FOR EACH STATION IN 2024\n",
    "\n",
    "# Clean the data. In this case, we have no interest in removing missing values. Rather,\n",
    "# we want to filter out any data not from the year 2024.\n",
    "gust_cleaned = dataframe \\\n",
    "    .filter(col(\"YEAR\") == 2024)\n",
    "\n",
    "# Compute total records and missing GUST data, grouped by name of station to get\n",
    "# distinct values for each. THIS RESULT DEPENDS ON WHAT YOU CONSIDER TO BE A MISSING\n",
    "# VALUE: NULL OR ANY ERRONEOUS CASE. I'M CONSIDERING ERRONEOUS DATA AS MISSING. THAT\n",
    "# IS, GUSTS OF 999.9 ARE MISSING.\n",
    "missing_gust = gust_cleaned \\\n",
    "    .groupBy(\"NAME\") \\\n",
    "    .agg(\n",
    "        count(\"*\").alias(\"total\"),  # Count total records per station\n",
    "        count(when(col(\"GUST\").isNull() | (col(\"GUST\") == \"999.9\"), True)).alias(\"missing\")  # Count missing values\n",
    "    )\n",
    "\n",
    "# Derive % from the above.\n",
    "missing_gust_pct = missing_gust \\\n",
    "    .withColumn(\"MISSING_%\", (col(\"missing\") / col(\"total\")) * 100) \\\n",
    "    .select(\"NAME\", \"MISSING_%\")\n",
    "\n",
    "missing_gust_pct.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
